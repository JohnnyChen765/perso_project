{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "# n_test = 10000\n",
    "# n_validation = 10000\n",
    "\n",
    "X, y = make_moons(n_samples = 10000, noise = 0.4)\n",
    "n_test = 0.2\n",
    "n_validation = 0.2"
   ]
  },
  {
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y example: {y[0]}\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(X[0].reshape(28, 28), cmap=\"binary\")\n",
    "# plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape: (10000, 2)\ny example: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = n_test, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = n_validation, random_state=42)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params : {'C': 100, 'gamma': 1}\nBest score : 0.8688333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Find best params for SVC\n",
    "params_grid = [\n",
    "    {\n",
    "        \"gamma\":  [0.1, 1, 10, 100],\n",
    "        \"C\" : [0.1, 1, 10, 100]\n",
    "    }\n",
    "]\n",
    "gaussian = SVC(kernel=\"rbf\")\n",
    "gaussian_search = GridSearchCV(gaussian, cv=5, param_grid=params_grid, refit=True)\n",
    "gaussian_search.fit(X_train, y_train)\n",
    "print(f\"Best params : {gaussian_search.best_params_}\")\n",
    "print(f\"Best score : {gaussian_search.best_score_}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params : {'max_depth': 10, 'max_leaf_nodes': 100, 'n_estimators': 1000}\nBest score : 0.8658333333333333\n"
     ]
    }
   ],
   "source": [
    "# Find best params for RandomForest\n",
    "params_randomForest = [\n",
    "    {\n",
    "        \"n_estimators\": [10, 100, 1000],\n",
    "        \"max_depth\" : [10, 100, 1000],\n",
    "        \"max_leaf_nodes\": [10 ,100, 1000]\n",
    "    }\n",
    "]\n",
    "randomForest = RandomForestClassifier(n_jobs=-1)\n",
    "randomForest_search = GridSearchCV(randomForest, cv=5, param_grid=params_randomForest, refit=True)\n",
    "randomForest_search.fit(X_train, y_train)\n",
    "print(f\"Best params : {randomForest_search.best_params_}\")\n",
    "print(f\"Best score : {randomForest_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params : {'n_estimators': 100}\nBest score : 0.8608333333333333\n"
     ]
    }
   ],
   "source": [
    "# Find best params for Adaboost\n",
    "params_adaboost = [\n",
    "    {\n",
    "        \"n_estimators\": [10, 100, 1000],\n",
    "    }\n",
    "]\n",
    "adaboost = AdaBoostClassifier(base_estimator = None)\n",
    "adaboost_search = GridSearchCV(adaboost, cv=5, param_grid=params_adaboost, refit=True)\n",
    "adaboost_search.fit(X_train, y_train)\n",
    "print(f\"Best params : {adaboost_search.best_params_}\")\n",
    "print(f\"Best score : {adaboost_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              SVC(C=100, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             ('random_forest',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=10,\n",
       "                                                     max_featu...\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=1000,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('adaboost',\n",
       "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                 base_estimator=None,\n",
       "                                                 learning_rate=1.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 random_state=None))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# On combine les différents modèles pour faire un modèle à vote\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "svm_votant = SVC(kernel=\"rbf\", **gaussian_search.best_params_)\n",
    "random_forest_votant = RandomForestClassifier(n_jobs=-1, **randomForest_search.best_params_)\n",
    "adaboost_votant = AdaBoostClassifier(**adaboost_search.best_params_)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('svc', svm_votant),\n",
    "        ('random_forest', random_forest_votant),\n",
    "        ('adaboost', adaboost_votant)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "# voting_clf = VotingClassifier(\n",
    "#     estimators = [\n",
    "#         ('svc', gaussian_search.best_estimator_),\n",
    "#         ('random_forest', randomForest_search.best_estimator_),\n",
    "#         ('adaboost',adaboost_search.best_estimator_)\n",
    "#     ],\n",
    "#     voting='hard'\n",
    "# )\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# voting_clf.score(X_validation, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Précisions sur le jeu de test: [0.8455, 0.8435, 0.8445, 0.8455]\n"
     ]
    }
   ],
   "source": [
    "estimators = [gaussian_search, randomForest_search, adaboost_search, voting_clf]\n",
    "scores = [estimator.score(X_test, y_test) for estimator in estimators]\n",
    "\n",
    "print(f\"Précisions sur le jeu de test: {scores}\")"
   ]
  }
 ]
}